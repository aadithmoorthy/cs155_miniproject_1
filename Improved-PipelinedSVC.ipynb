{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models trained on full training dataset.  \n",
    "\n",
    "Pipeline is as follows:  \n",
    "1) Data is word counts  \n",
    "2) Data is sent through PCA with whitening  \n",
    "3) Cross validation is used to chose the best L1-regularized LinearSVC  \n",
    "4) The LinearSVC defines the subspace of features used for final SVC  \n",
    "5) Cross validation is used to choose the best RBF SVC on reduced feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_unsplit_data, get_test_data\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "X_train, y_train, = get_unsplit_data()\n",
    "X_test = get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitened PCA based on input data\n",
    "PCA_white = PCA(whiten=True)\n",
    "PCA_white.fit(X_train)\n",
    "\n",
    "# Transform training and test data\n",
    "X_train_PCA_white = PCA_white.transform(X_train)\n",
    "X_test_PCA_white = PCA_white.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Stage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate_L1_LinearSVC(X_t, y_t, C_params, K_folds):\n",
    "    \n",
    "    start = time.time()\n",
    "    # Set parameters to be crossvalidated\n",
    "    tuned_parameters = [{'loss':['squared_hinge'], 'penalty':['l1'], 'dual':[False], 'C': C_params}]\n",
    "    # Perform cross validation\n",
    "    clf = GridSearchCV(LinearSVC(), tuned_parameters, cv=K_folds, scoring='accuracy')\n",
    "    clf.fit(X_t, y_t)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"L1 Cross-validation Training Time = \", (end - start))\n",
    "    print()\n",
    "\n",
    "    print(\"Grid scores:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    print(\"Best parameter set:\")\n",
    "    print(clf.best_params_)\n",
    "    bestmodel = clf.best_estimator_\n",
    "    N_coef = np.sum(bestmodel.coef_[0] != 0)\n",
    "    N_dim = len(bestmodel.coef_[0])\n",
    "    print(\"Dimensionality of model: %s of %s\" % (N_coef, N_dim))\n",
    "    print()\n",
    "    \n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate_final_rbfSVC(X_t, y_t, C_params, G_params, K_folds):\n",
    "    \n",
    "    start = time.time()\n",
    "    # Set parameters to be crossvalidated\n",
    "    tuned_parameters = [{'C': C_params, 'gamma': G_params, 'kernel':['rbf'], 'cache_size':[2000]}]\n",
    "    # Perform cross validation\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=K_folds, scoring='accuracy', n_jobs=4)\n",
    "    clf.fit(X_t, y_t)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Final RBF SVC Cross-validation Training Time = \", (end - start))\n",
    "    print()\n",
    "\n",
    "    print(\"Grid scores:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "    print(\"Best parameter set:\")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    \n",
    "    print(\"Retraining model for decision probabilities\")\n",
    "    best_param = clf.best_params_\n",
    "    best_param['probability'] = True\n",
    "    \n",
    "    start = time.time()\n",
    "    # Train Final Model\n",
    "    model = SVC(**best_param)\n",
    "    model.fit(X_t, y_t)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Final RBF SVC Training Time = \", (end - start))\n",
    "    print()\n",
    "    \n",
    "    nSupp = len(model.support_)\n",
    "    fCorr = np.sum(model.predict(X_t) == y_t)/len(y_t)\n",
    "    print(\"Number of Support Vectors = \", nSupp)\n",
    "    print(\"Training Accuracy = \", fCorr)\n",
    "    print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(final_model, X_PCA_test_reduced):\n",
    "    # Predict labels of dataset\n",
    "    y_labels = final_model.predict(X_PCA_test_reduced)\n",
    "    # Prediction probabilities\n",
    "    y_probs = final_model.predict_proba(X_PCA_test_reduced)\n",
    "    return [y_labels, y_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_labels(y_label, file_prefix):\n",
    "    y_label = y_label.reshape((len(y_label),1))\n",
    "    result_col_1 = (np.array(range(len(y_label)))+1).reshape((len(y_label),1))\n",
    "    result = np.concatenate((result_col_1,y_label), axis = 1)\n",
    "    np.savetxt(file_prefix + \"_pred_labels.txt\", result, fmt=\"%d\", delimiter=',', header='Id,Prediction')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_probs(y_probs, file_prefix):\n",
    "    result_col_1 = (np.array(range(len(y_probs[:,0])))+1).reshape((len(y_probs[:,0]),1))\n",
    "    result = np.concatenate((result_col_1,y_probs), axis = 1)\n",
    "    np.savetxt(file_prefix + \"_pred_probs.txt\", result, fmt=[\"%d\", \"%f\", \"%f\"], delimiter=',', header='Id,P[0],P[1]')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbfSVC_pipeline(PCA_model, X_t, y_t, X_v, C_init, K_init, C_final, G_final, K_final, file_prefix):\n",
    "    # Save PCA model\n",
    "    pickle.dump( PCA_model, open( file_prefix + \"_pca.p\", \"wb\" ) )\n",
    "    # Train L1-regularized linear SVC for dimension reduction\n",
    "    reducing_model = crossvalidate_L1_LinearSVC(X_t, y_t, C_init, K_init)\n",
    "    # Save model\n",
    "    pickle.dump( reducing_model, open( file_prefix + \"_reducing_svc.p\", \"wb\" ) )\n",
    "    # Reduce dimension of dataset\n",
    "    X_t_reduced = X_t[:,(reducing_model.coef_ != 0)[0]]\n",
    "    X_v_reduced = X_v[:,(reducing_model.coef_ != 0)[0]]\n",
    "    # Train final rbf SVC\n",
    "    final_model = crossvalidate_final_rbfSVC(X_t_reduced, y_t, C_final, G_final, K_final)\n",
    "    # Save model\n",
    "    pickle.dump( final_model, open( file_prefix + \"_final_svc.p\", \"wb\" ) )\n",
    "    # Predict test labels and probabilities\n",
    "    [y_label, y_prob] = predict_test_data(final_model, X_v_reduced)\n",
    "    # Save labels and probabilities\n",
    "    save_predicted_labels(y_label, file_prefix)\n",
    "    save_predicted_probs(y_prob, file_prefix)\n",
    "    return [reducing_model, final_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF SVC trained on whitened PCA of raw data\n",
    "\n",
    "C_i = np.logspace(-3,0,10)\n",
    "K_i = 10\n",
    "\n",
    "C_f = np.logspace(-4,2,13)\n",
    "G_f = np.logspace(-4,0,9)\n",
    "K_f = 5\n",
    "\n",
    "fileprefix = 'Final_Pipeline_'\n",
    "\n",
    "[rModel, fModel] = rbfSVC_pipeline(PCA_white, X_train_PCA_white, y_train, X_test_PCA_white, C_i, K_i, C_f, G_f, K_f, fileprefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "    \n",
    "L1 Cross-validation Training Time =  452.21334862709045  \n",
    "\n",
    "Best parameter set found on development set:  \n",
    "{'penalty': 'l1', 'C': 0.01, 'loss': 'squared_hinge', 'dual': False}  \n",
    "Dimensionality of model: 818 of 1000  \n",
    "\n",
    "Final RBF SVC Cross-validation Training Time =  11110.732734203339  \n",
    "\n",
    "Best parameter set found on development set:  \n",
    "{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001, 'cache_size': 2000}  \n",
    "\n",
    "Retraining model for decision probabilities  \n",
    "Final RBF SVC Training Time =  1113.8617765903473  \n",
    "\n",
    "Number of Support Vectors =  9161  \n",
    "Training Accuracy =  0.89405  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
